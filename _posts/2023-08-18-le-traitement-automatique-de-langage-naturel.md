---
published: false
---
L'autre jour j'ai lu sur le sujet du traitement automatique de langage naturel (natural language processing ou NLP en anglais) et ça m'a aidé à comprendre la base de cette technologie.

Le sujet qui m'a le plus marqué est un mécanisme qui est bien nommé Attention. C'est une relativement nouvelle technique qui était inventé en 2016 et qui est souvent utilisé de nos jours pour des tâches de traduction. L'idée générale est plutôt simple : chaque fois que le réseau neuronal produit un mot de la traduction, it fait le choix de mot en fonction des mots de l'entrée qu'il juge important, des mots auxquels il fait attention. attention à certains mots de l'entrée ainsi que d'autres mots dans la sortie. Grâce à cela, il peut traduire beaucoup plus précisement. Bien sûr, c'est une explication simpliste et les maths dèrièrre est beaucoup plus difficile. En tout cas, je crois que c'est important d'avoir une connaissance de base de cette nouvelle technologie qui se met au jour très rapidement.

Après avoir lu, ça fait du sens parce que je constate que des traducteurs comme Google Translate est devenu beaucoup mieux vers ce temps. En effet, on utilise le mécani	sm Attention pour Google Translate.
