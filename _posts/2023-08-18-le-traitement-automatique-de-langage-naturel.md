---
published: false
---
L'autre jour j'ai lu sur le sujet du traitement automatique de langage naturel (natural language processing ou NLP en anglais) et ça m'a aidé à comprendre la base de cette technologie.

Le sujet qui m'a le plus marqué est un mécanisme qui est bien nommé Attention. C'est une relativement nouvelle technique qui était inventé en 2016 et qui est souvent utilisé de nos jours pour des tâches de traduction. L'idée générale est plutôt simple : chaque fois que le réseau neuronal produit un mot de la traduction, it fait le choix de mot en fonction des mots de l'entrée qu'il juge important, des mots auxquels il fait attention. attention à certains mots de l'entrée ainsi que d'autres mots dans la sortie. Grâce à cela, il peut traduire beaucoup plus précisement. Je constate

Un exemple précise : prenons la phrase "The agreement on the European Economic Area was signed in August 1992." 

Ce modèle a été inventé en 2015 et ça fais du sens parce que je constate que des traducteurs comme Google Translate est devenu beaucoup mieux vers ce temps. En effet, on utilise le mécanism Attention pour Google Translate.
